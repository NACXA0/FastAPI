#å®‰è£…ç¯å¢ƒåŒ…pip install zhipuai
'''APIKeyï¼š'''
'''ä¸‰ç§APIè°ƒç”¨æ–¹å¼
åŒæ­¥è°ƒç”¨ï¼šzhipuai.model_api.invoke()è°ƒç”¨åå³å¯ä¸€æ¬¡æ€§è·å¾—æœ€ç»ˆç»“æœ
å¼‚æ­¥è°ƒç”¨ï¼šzhipuai.model_api.async_invoke()è°ƒç”¨åä¼šç«‹å³è¿”å›ä¸€ä¸ªä»»åŠ¡ ID ï¼Œç„¶åç”¨ä»»åŠ¡IDæŸ¥è¯¢è°ƒç”¨ç»“æœï¼ˆæ ¹æ®æ¨¡å‹å’Œå‚æ•°çš„ä¸åŒï¼Œé€šå¸¸éœ€è¦ç­‰å¾…10-30ç§’æ‰èƒ½å¾—åˆ°æœ€ç»ˆç»“æœ
SSEè°ƒç”¨ï¼šzhipuai.model_api.sse_invoke()è°ƒç”¨åå¯ä»¥æµå¼çš„å®æ—¶è·å–åˆ°ç»“æœç›´åˆ°ç»“æŸ
'''
import zhipuai
zhipuai.api_key = "5abc1fc2f19d7f09f4aa7c5394c528c7.v8MCrNVNWfYusjBs"

def chat():
    response = {'code': 200, 'msg': 'æ“ä½œæˆåŠŸ',
                'data': {'request_id': '7768921906578633313',
                         'task_id': '7768921906578633313',
                         'task_status': 'SUCCESS',
                         'choices': [{'role': 'assistant', 'content': '"ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚"'}], 'usage': {'total_tokens': 27}},
                'success': True}


    #zhipuai.model_api.invoke(
    #    model="chatglm_lite",
    #    prompt=[{"role":"user","content":"ä½ å¥½"}],
    #    top_p = 0.7,
    #    temperature = 0.9,
    #)
    return response

#Question = input("è¾“å…¥ï¼š")
print(chat()["data"]["choices"][0]["content"])
